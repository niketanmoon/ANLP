{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a821d941",
   "metadata": {},
   "source": [
    "<h3 style = \"font-size:60px; font-family:Garamond ; font-weight : normal; background-color: #f6f5f5 ; color : #fe346e; text-align: center; border-radius: 100px 100px;\">Importing the libraries</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f76b7e6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/niketan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/niketan/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /Users/niketan/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# For tokenization\n",
    "import nltk\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# For word lemmatization\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439e16d5",
   "metadata": {},
   "source": [
    "<h3 style = \"font-size:60px; font-family:Garamond ; font-weight : normal; background-color: #f6f5f5 ; color : #fe346e; text-align: center; border-radius: 100px 100px;\">Importing the Dataset</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b8d88f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 83032: expected 6 fields, saw 7\\n'\n",
      "b'Skipping line 154657: expected 6 fields, saw 7\\n'\n",
      "b'Skipping line 323916: expected 6 fields, saw 7\\n'\n"
     ]
    }
   ],
   "source": [
    "originalData = pd.read_csv('data.tsv', sep=\"\\t\", on_bad_lines=\"warn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15f6e1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = originalData"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0427c4f1",
   "metadata": {},
   "source": [
    "<h3 style = \"font-size:60px; font-family:Garamond ; font-weight : normal; background-color: #f6f5f5 ; color : #fe346e; text-align: center; border-radius: 100px 100px;\">Data Exploration</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65f8071c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>133273</td>\n",
       "      <td>213221</td>\n",
       "      <td>213222.0</td>\n",
       "      <td>How is the life of a math student? Could you d...</td>\n",
       "      <td>Which level of prepration is enough for the ex...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>402555</td>\n",
       "      <td>536040</td>\n",
       "      <td>536041.0</td>\n",
       "      <td>How do I control my horny emotions?</td>\n",
       "      <td>How do you control your horniness?</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>360472</td>\n",
       "      <td>364011</td>\n",
       "      <td>490273.0</td>\n",
       "      <td>What causes stool color to change to yellow?</td>\n",
       "      <td>What can cause stool to come out as little balls?</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>150662</td>\n",
       "      <td>155721</td>\n",
       "      <td>7256.0</td>\n",
       "      <td>What can one do after MBBS?</td>\n",
       "      <td>What do i do after my MBBS ?</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>183004</td>\n",
       "      <td>279958</td>\n",
       "      <td>279959.0</td>\n",
       "      <td>Where can I find a power outlet for my laptop ...</td>\n",
       "      <td>Would a second airport in Sydney, Australia be...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id    qid1      qid2  \\\n",
       "0  133273  213221  213222.0   \n",
       "1  402555  536040  536041.0   \n",
       "2  360472  364011  490273.0   \n",
       "3  150662  155721    7256.0   \n",
       "4  183004  279958  279959.0   \n",
       "\n",
       "                                           question1  \\\n",
       "0  How is the life of a math student? Could you d...   \n",
       "1                How do I control my horny emotions?   \n",
       "2       What causes stool color to change to yellow?   \n",
       "3                        What can one do after MBBS?   \n",
       "4  Where can I find a power outlet for my laptop ...   \n",
       "\n",
       "                                           question2  is_duplicate  \n",
       "0  Which level of prepration is enough for the ex...           0.0  \n",
       "1                 How do you control your horniness?           1.0  \n",
       "2  What can cause stool to come out as little balls?           0.0  \n",
       "3                       What do i do after my MBBS ?           1.0  \n",
       "4  Would a second airport in Sydney, Australia be...           0.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "430ed698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 363192 entries, 0 to 363191\n",
      "Data columns (total 6 columns):\n",
      " #   Column        Non-Null Count   Dtype  \n",
      "---  ------        --------------   -----  \n",
      " 0   id            363192 non-null  object \n",
      " 1   qid1          363192 non-null  object \n",
      " 2   qid2          363185 non-null  float64\n",
      " 3   question1     363181 non-null  object \n",
      " 4   question2     363180 non-null  object \n",
      " 5   is_duplicate  363180 non-null  float64\n",
      "dtypes: float64(2), object(4)\n",
      "memory usage: 16.6+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1df8062",
   "metadata": {},
   "source": [
    "<h3 style = \"font-size:60px; font-family:Garamond ; font-weight : normal; background-color: #f6f5f5 ; color : #fe346e; text-align: center; border-radius: 100px 100px;\">Data Preprocessing</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f0adfb",
   "metadata": {},
   "source": [
    "<h4 style = \"font-size:40px; font-family:Garamond ; font-weight : normal; background-color: #f6f5f5 ; color : #fe346e; text-align: center; border-radius: 100px 100px;\">Dropping the rows with null values</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8127d1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9398811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 363177 entries, 0 to 363191\n",
      "Data columns (total 6 columns):\n",
      " #   Column        Non-Null Count   Dtype  \n",
      "---  ------        --------------   -----  \n",
      " 0   id            363177 non-null  object \n",
      " 1   qid1          363177 non-null  object \n",
      " 2   qid2          363177 non-null  float64\n",
      " 3   question1     363177 non-null  object \n",
      " 4   question2     363177 non-null  object \n",
      " 5   is_duplicate  363177 non-null  float64\n",
      "dtypes: float64(2), object(4)\n",
      "memory usage: 19.4+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ac9754",
   "metadata": {},
   "source": [
    "<span style=\"color:brown; font-size:16px\">The rows dropped from 363192 to 363177. There were 15 rows with null values</span>\n",
    "<br> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23af6bf9",
   "metadata": {},
   "source": [
    "<h4 style = \" font-family:Garamond ; font-weight : normal; background-color: #f6f5f5 ; color : #fe346e; border-radius: 100px 100px;\"><span style=\"text-align:left; margin-left: 20px; padding:10px; font-size:30px;\">Similarly dropping all the rows that has duplicate question2</span></h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d106ee9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop_duplicates([\"question2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "431ebdbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 272959 entries, 0 to 363190\n",
      "Data columns (total 6 columns):\n",
      " #   Column        Non-Null Count   Dtype  \n",
      "---  ------        --------------   -----  \n",
      " 0   id            272959 non-null  object \n",
      " 1   qid1          272959 non-null  object \n",
      " 2   qid2          272959 non-null  float64\n",
      " 3   question1     272959 non-null  object \n",
      " 4   question2     272959 non-null  object \n",
      " 5   is_duplicate  272959 non-null  float64\n",
      "dtypes: float64(2), object(4)\n",
      "memory usage: 14.6+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756974e2",
   "metadata": {},
   "source": [
    "<span style=\"color:brown; font-size:16px\">Now the rows dropped from 363177 to 272959. There were 90218 rows where the question2 values were equal.</span>\n",
    "<br> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89138d2d",
   "metadata": {},
   "source": [
    "<h3 style = \"font-size:60px; font-family:Garamond ; font-weight : normal; background-color: #f6f5f5 ; color : #fe346e; text-align: center; border-radius: 100px 100px;\">Text Preprocessing</h3>\n",
    "<h4 style=\"font-size:25px; font-family:Garamond ; font-weight : normal; background-color: #f6f5f5 ; color : #fe346e; border-radius: 30px 30px\">\n",
    "    <br>\n",
    "    <ol>1. Data Cleaning</ol>\n",
    "    <ol>2. Tokenization and stop words removal</ol>\n",
    "    <ol>3. Lemmatization</ol>\n",
    "</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324c7b82",
   "metadata": {},
   "source": [
    "<h4 style = \"font-size:30px; font-family:Garamond ; font-weight : normal; background-color: #f6f5f5 ; color : #fe346e; text-align: center; border-radius: 100px 100px;\">1. Data Cleaning</h4>\n",
    "<h5 style=\"font-size:25px; font-family:Garamond ; font-weight : normal; background-color: #f6f5f5 ; color : #fe346e; border-radius: 30px 30px\">\n",
    "    <br>\n",
    "    <ol>1. Removing punctuation</ol>\n",
    "    <ol>2. Removing numbers</ol>\n",
    "    <ol>3. Removing html tags</ol>\n",
    "    <ol>4. Removing urls</ol>\n",
    "    <ol>5.Converting the text to lower case</ol>\n",
    "</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "704e4a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(q):\n",
    "    return re.sub(r'[^\\w\\s]', \"\", q)\n",
    "\n",
    "def remove_numbers(q):\n",
    "    return re.sub(r'[\\d+]', \"\", q)\n",
    "\n",
    "def remove_html_tags(q):\n",
    "    \"\"\"\n",
    "        This takes care of the html tags as well as &nsbm similar characters\n",
    "        which are not specifically enclosed in html tags\n",
    "    \"\"\"  \n",
    "    c_rule = re.compile('<.*?>|&([a-z0-9]+|#[0-9]{1,6}|#x[0-9a-f]{1,6});')\n",
    "    return re.sub(c_rule,'', q)\n",
    "\n",
    "def remove_urls(q):\n",
    "    return re.sub('https://.*', '', q)\n",
    "\n",
    "\n",
    "def convert_to_lowercase(q):\n",
    "    return q.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1dcb8dc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.09 s, sys: 16.5 ms, total: 1.1 s\n",
      "Wall time: 1.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data[\"question2\"] = data.question2.apply(remove_punctuation)\n",
    "data[\"question2\"] = data.question2.apply(remove_numbers)\n",
    "data[\"question2\"] = data.question2.apply(remove_html_tags)\n",
    "data[\"question2\"] = data.question2.apply(remove_urls)\n",
    "data[\"question2\"] = data.question2.apply(convert_to_lowercase)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fbe9c83",
   "metadata": {},
   "source": [
    "<h4 style = \"font-size:30px; font-family:Garamond ; font-weight : normal; background-color: #f6f5f5 ; color : #fe346e; text-align: center; border-radius: 100px 100px;\">2. Tokenization and Stop Words Removal</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "21225bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the stopwords list\n",
    "stopwords_list = set(stopwords.words(\"english\"))\n",
    "def apply_tokenization_and_remove_stopwords(review):\n",
    "    # Applying tokenization\n",
    "    tokenizer = ToktokTokenizer()\n",
    "    tokens = tokenizer.tokenize(review)\n",
    "    tokens = [token.strip() for token in tokens]\n",
    "    # applying removal of stopwords\n",
    "    review_no_stopwords = [word for word in tokens if word not in stopwords_list]\n",
    "    return \" \".join(review_no_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "73e0e280",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"question2\"] = data.question2.apply(apply_tokenization_and_remove_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed6b9ee",
   "metadata": {},
   "source": [
    "<h4 style = \"font-size:30px; font-family:Garamond ; font-weight : normal; background-color: #f6f5f5 ; color : #fe346e; text-align: center; border-radius: 100px 100px;\">3. Lemmatization</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4462fa25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the text to root word - eg. low, lower, lowest converted to low\n",
    "def apply_lemmatization(review):\n",
    "    lemmatized_review = []\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokenizer = ToktokTokenizer()\n",
    "    tokens = tokenizer.tokenize(review)\n",
    "    tokens = [token.strip() for token in tokens]\n",
    "    for w in tokens:\n",
    "        lemmatized_review.append(lemmatizer.lemmatize(w))\n",
    "    return \" \".join(lemmatized_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "989e866f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"question2\"] = data.question2.apply(apply_lemmatization)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb336745",
   "metadata": {},
   "source": [
    "<h3 style = \"font-size:60px; font-family:Garamond ; font-weight : normal; background-color: #f6f5f5 ; color : #fe346e; text-align: center; border-radius: 100px 100px;\">Inverted File Mapping</h3>\n",
    "<h5 style=\"font-size:25px; font-family:Garamond ; font-weight : normal; background-color: #f6f5f5 ; color : #fe346e; border-radius: 30px 30px\">\n",
    "    <br>\n",
    "    <ol>1. First Calculate TF IDF Score</ol>\n",
    "    <ol>2. Map the word with (doc, score) in a inverted file map</ol>\n",
    "</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "00f56091",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MapInvertFile:\n",
    "    def __init__(self):\n",
    "        self.N = 0\n",
    "        self.invertFile = {} # word - (docid, tfidf score)\n",
    "        self.numberOfWordInDoc = {}\n",
    "        self.wordInDocuments = {}\n",
    "        self.tfWord = {}\n",
    "    \n",
    "    def getCountTermInDocument(self, ids, questions):\n",
    "        for doc, q in zip(ids, questions):\n",
    "            for w in q.split():\n",
    "                if (doc, w) not in self.numberOfWordInDoc:\n",
    "                    self.numberOfWordInDoc[(doc, w)] = 1\n",
    "                else:\n",
    "                    self.numberOfWordInDoc[(doc,w)] += 1\n",
    "                    \n",
    "                # mapping document in which word exists\n",
    "                if w not in self.wordInDocuments:\n",
    "                    self.wordInDocuments[w] = {doc}\n",
    "                else:\n",
    "                    self.wordInDocuments[w].add(doc)\n",
    "    \n",
    "    # This function only calculate tf\n",
    "    def calculateTF(self):\n",
    "        for (doc, w) in self.numberOfWordInDoc:\n",
    "            self.tfWord[(doc, w)] = np.log(1 + self.numberOfWordInDoc[(doc, w)])\n",
    "    \n",
    "    def setInvertedFile(self):\n",
    "        for (doc, w) in self.tfWord:\n",
    "            # calculate idf score\n",
    "            idf = self.N/len(self.wordInDocuments[w])\n",
    "            \n",
    "            # calculate tfidf score\n",
    "            self.tfWord[(doc, w)] = self.tfWord[(doc, w)] * idf\n",
    "            tfIdfScore = self.tfWord[(doc, w)]\n",
    "            \n",
    "            # converting to invert file data structure\n",
    "            if w not in self.invertFile:\n",
    "                self.invertFile[w] = [(doc, tfIdfScore)]\n",
    "            else:\n",
    "                self.invertFile[w].append((doc, tfIdfScore))\n",
    "            \n",
    "    def getInvertedFile(self, data):\n",
    "        ids = data.id.to_list()\n",
    "        questions = data.question2.to_list()\n",
    "        self.N = len(ids)\n",
    "        self.getCountTermInDocument(ids, questions)\n",
    "        self.calculateTF()\n",
    "        self.setInvertedFile()\n",
    "        return self.invertFile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e489fa61",
   "metadata": {},
   "source": [
    "<h3 style = \"font-size:30px; font-family:Garamond ; font-weight : normal; background-color: #f6f5f5 ; color : #fe346e; text-align: center; border-radius: 100px 100px;\"> Get the Inverted File Mapping</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8cfe9dbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.12 s, sys: 95.9 ms, total: 3.21 s\n",
      "Wall time: 3.21 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "instance = MapInvertFile()\n",
    "invertedFileMap = instance.getInvertedFile(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0415b2",
   "metadata": {},
   "source": [
    "<h3 style = \"font-size:60px; font-family:Garamond ; font-weight : normal; background-color: #f6f5f5 ; color : #fe346e; text-align: center; border-radius: 100px 100px;\">Text Matching for Inverted File</h3>\n",
    "<br>\n",
    "<br>\n",
    "<span style=\"font-size:25px; font-family:Garamond ; font-weight : normal; background-color: #f6f5f5 ; color : #fe346e; border-radius: 30px 30px\">For this we have to match first 100 queries in question1 where is_duplicate = True</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fbd7c9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataH = data[data.is_duplicate == 1.0][:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cef2105b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>402555</td>\n",
       "      <td>536040</td>\n",
       "      <td>536041.0</td>\n",
       "      <td>How do I control my horny emotions?</td>\n",
       "      <td>control horniness</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>150662</td>\n",
       "      <td>155721</td>\n",
       "      <td>7256.0</td>\n",
       "      <td>What can one do after MBBS?</td>\n",
       "      <td>mbbs</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>106969</td>\n",
       "      <td>147570</td>\n",
       "      <td>787.0</td>\n",
       "      <td>What is the best self help book you have read?...</td>\n",
       "      <td>top self help book read</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>233239</td>\n",
       "      <td>71243</td>\n",
       "      <td>177376.0</td>\n",
       "      <td>What will be Hillary Clinton's policy towards ...</td>\n",
       "      <td>hilary clinton policy towards india become pre...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>11568</td>\n",
       "      <td>22332</td>\n",
       "      <td>22333.0</td>\n",
       "      <td>Which is the best book to study TENSOR for gen...</td>\n",
       "      <td>best book tensor calculus</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>211943</td>\n",
       "      <td>108779</td>\n",
       "      <td>150467.0</td>\n",
       "      <td>Is there a directory of landline individual ph...</td>\n",
       "      <td>directory individual landline cell phone telep...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>351813</td>\n",
       "      <td>480691</td>\n",
       "      <td>480692.0</td>\n",
       "      <td>Which operating system do Google engineers use?</td>\n",
       "      <td>operating system programmer developer google use</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>212168</td>\n",
       "      <td>317182</td>\n",
       "      <td>317183.0</td>\n",
       "      <td>What is 0 divided by infinity?</td>\n",
       "      <td>divided</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>402628</td>\n",
       "      <td>85510</td>\n",
       "      <td>23367.0</td>\n",
       "      <td>Is there proof that alien life exists?</td>\n",
       "      <td>evidence alien life space</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>270328</td>\n",
       "      <td>388203</td>\n",
       "      <td>388204.0</td>\n",
       "      <td>What is the exam pattern for CAT 2016?</td>\n",
       "      <td>pattern cat</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id    qid1      qid2  \\\n",
       "1    402555  536040  536041.0   \n",
       "3    150662  155721    7256.0   \n",
       "7    106969  147570     787.0   \n",
       "11   233239   71243  177376.0   \n",
       "13    11568   22332   22333.0   \n",
       "..      ...     ...       ...   \n",
       "251  211943  108779  150467.0   \n",
       "259  351813  480691  480692.0   \n",
       "262  212168  317182  317183.0   \n",
       "268  402628   85510   23367.0   \n",
       "269  270328  388203  388204.0   \n",
       "\n",
       "                                             question1  \\\n",
       "1                  How do I control my horny emotions?   \n",
       "3                          What can one do after MBBS?   \n",
       "7    What is the best self help book you have read?...   \n",
       "11   What will be Hillary Clinton's policy towards ...   \n",
       "13   Which is the best book to study TENSOR for gen...   \n",
       "..                                                 ...   \n",
       "251  Is there a directory of landline individual ph...   \n",
       "259    Which operating system do Google engineers use?   \n",
       "262                     What is 0 divided by infinity?   \n",
       "268             Is there proof that alien life exists?   \n",
       "269             What is the exam pattern for CAT 2016?   \n",
       "\n",
       "                                             question2  is_duplicate  \n",
       "1                                    control horniness           1.0  \n",
       "3                                                 mbbs           1.0  \n",
       "7                              top self help book read           1.0  \n",
       "11   hilary clinton policy towards india become pre...           1.0  \n",
       "13                           best book tensor calculus           1.0  \n",
       "..                                                 ...           ...  \n",
       "251  directory individual landline cell phone telep...           1.0  \n",
       "259   operating system programmer developer google use           1.0  \n",
       "262                                            divided           1.0  \n",
       "268                          evidence alien life space           1.0  \n",
       "269                                        pattern cat           1.0  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1427d638",
   "metadata": {},
   "source": [
    "<h3 style = \"font-size:30px; font-family:Garamond ; font-weight : normal; background-color: #f6f5f5 ; color : #fe346e; text-align: center; border-radius: 100px 100px;\">Apply Text preprocessing techniques on question1</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ff471653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 25.6 ms, sys: 678 µs, total: 26.2 ms\n",
      "Wall time: 26 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dataH[\"question1\"] = dataH.question1.apply(remove_punctuation)\n",
    "dataH[\"question1\"] = dataH.question1.apply(remove_numbers)\n",
    "dataH[\"question1\"] = dataH.question1.apply(remove_html_tags)\n",
    "dataH[\"question1\"] = dataH.question1.apply(remove_urls)\n",
    "dataH[\"question1\"] = dataH.question1.apply(convert_to_lowercase)\n",
    "dataH[\"question1\"] = dataH.question1.apply(apply_tokenization_and_remove_stopwords)\n",
    "dataH[\"question1\"] = dataH.question1.apply(apply_lemmatization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "79b7ade7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextMatching:\n",
    "    def __init__(self):\n",
    "        self.question5DocRank = {}\n",
    "        self.question2DocRank = {}\n",
    "    \n",
    "    def getTop5TextMatching(self, dataset):\n",
    "        ids = dataset.id.to_list()\n",
    "        questions = dataset.question1.to_list()\n",
    "        for (doc, question1) in zip(ids, questions):\n",
    "            docRank = {}\n",
    "            for w in question1.split():\n",
    "                if w in invertedFileMap:\n",
    "                    for (d, s) in invertedFileMap[w]:\n",
    "                        if d not in docRank:\n",
    "                            docRank[d] = s\n",
    "                        else:\n",
    "                            docRank[d] += s\n",
    "            top5Questions = sorted(docRank, key=docRank.get, reverse=True)[:5]\n",
    "            self.question5DocRank[(doc, question1)] = top5Questions\n",
    "        return self.question5DocRank\n",
    "    \n",
    "    def getTop2TextMatching(self, dataset):\n",
    "        ids = dataset.id.to_list()\n",
    "        questions = dataset.question1.to_list()\n",
    "        for (doc, question1) in zip(ids, questions):\n",
    "            docRank = {}\n",
    "            for w in question1.split():\n",
    "                if w in invertedFileMap:\n",
    "                    for (d, s) in invertedFileMap[w]:\n",
    "                        if d not in docRank:\n",
    "                            docRank[d] = s\n",
    "                        else:\n",
    "                            docRank[d] += s\n",
    "            top2Questions = sorted(docRank, key=docRank.get, reverse=True)[:2]\n",
    "            self.question2DocRank[(doc, question1)] = top2Questions\n",
    "        return self.question2DocRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "de35c5d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 357 ms, sys: 9.61 ms, total: 366 ms\n",
      "Wall time: 365 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tmInstance = TextMatching()\n",
    "top5Docs = tmInstance.getTop5TextMatching(dataH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8438f00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return top 5 questions instead of document ids\n",
    "with open(\"invertedFileTextMatchingOutput.txt\", \"w\") as f:\n",
    "    for (doc, q) in top5Docs:\n",
    "        q1 = originalData[originalData.id == doc].question1.to_list()[0]\n",
    "        q2 = originalData[originalData.id.isin(top5Docs[(doc, q)])].question2.to_list()\n",
    "        f.write(\"******************\\n\")\n",
    "        f.write(f\"{q1}\\n\")\n",
    "        f.write(f\"{q2}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df94846",
   "metadata": {},
   "source": [
    "<h3 style = \"font-size:60px; font-family:Garamond ; font-weight : normal; background-color: #f6f5f5 ; color : #fe346e; text-align: center; border-radius: 100px 100px;\">Performance Evaluation</h3>\n",
    "<br>\n",
    "<br>\n",
    "<span style=\"font-size:25px; font-family:Garamond ; font-weight : normal; background-color: #f6f5f5 ; color : #fe346e; border-radius: 30px 30px\">Probability top5 vs top2</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f0aab449",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Performance:\n",
    "    def __init__(self):\n",
    "        self.totalLen = 0\n",
    "        self.truth = 0\n",
    "    \n",
    "    def getProbability(self, dataset, questionDoc):\n",
    "        ids = dataset.id.to_list()\n",
    "        self.totalLen = len(ids)\n",
    "        for (doc, q) in questionDoc:\n",
    "            if doc in questionDoc[(doc,q)]:\n",
    "                self.truth += 1\n",
    "        return (self.truth / self.totalLen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "77802941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability for ground truth with top 5 docs is 0.37\n",
      "Probability for ground truth with top 2 docs is 0.23\n"
     ]
    }
   ],
   "source": [
    "secondInstance = TextMatching()\n",
    "top2Docs = secondInstance.getTop2TextMatching(dataH)\n",
    "\n",
    "prob5 = Performance()\n",
    "top5Prob = prob5.getProbability(dataH, top5Docs)\n",
    "prob2 = Performance()\n",
    "top2Prob = prob2.getProbability(dataH, top2Docs)\n",
    "\n",
    "print(f\"Probability for ground truth with top 5 docs is {top5Prob}\")\n",
    "print(f\"Probability for ground truth with top 2 docs is {top2Prob}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64bf36df",
   "metadata": {},
   "source": [
    "<h3 style = \"font-size:60px; font-family:Garamond ; font-weight : normal; background-color: #f6f5f5 ; color : #fe346e; text-align: center; border-radius: 100px 100px;\">Search question</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a8b88dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def searchQuestionMatch(question):\n",
    "    # it should go through text preprocessing phase\n",
    "    question = remove_punctuation(question)\n",
    "    question = remove_numbers(question)\n",
    "    question = remove_html_tags(question)\n",
    "    question = remove_urls(question)\n",
    "    question = convert_to_lowercase(question)\n",
    "    question = apply_tokenization_and_remove_stopwords(question)\n",
    "    question = apply_lemmatization(question)\n",
    "    \n",
    "    wordList = question.split()\n",
    "    docRank = {}\n",
    "    for w in wordList:\n",
    "        if w in invertedFileMap:\n",
    "            for (d, s) in invertedFileMap[w]:\n",
    "                if d not in docRank:\n",
    "                    docRank[d] = s\n",
    "                else:\n",
    "                    docRank[d] += s\n",
    "    top5 = sorted(docRank, key=docRank.get, reverse=True)[:5]\n",
    "    return top5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "077f3152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your question: How to do MBBS?\n"
     ]
    }
   ],
   "source": [
    "question = input(\"Enter your question: \")\n",
    "topMatches = searchQuestionMatch(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "48cf1e02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What do i do after my MBBS ?',\n",
       " 'What is the process of getting a surgical residency in UK after completing MBBS from India?',\n",
       " 'Is it true that in order to get admission to usa after mbbs in india, ur medical college should be aiims only or u enter only on the basis of usmle? Basically does being from a good medical college in india guarantee you admission in usa or canada or some other country after mbbs or does it help?',\n",
       " 'I am first year MBBS student(ST) in one of new Aiims.I feel inferior to others due to my rank in entrance exam.can I get good results in MBBS exams?',\n",
       " 'How can I transfer from my MBBS medical college to another in Maharashtra after the 1st year of the MBBS?']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Return the questions instead of document id\n",
    "tmatches = originalData[originalData.id.isin(topMatches)].question2.to_list()\n",
    "tmatches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320faa91",
   "metadata": {},
   "source": [
    "<h3 style = \"font-size:60px; font-family:Garamond ; font-weight : normal; background-color: #f6f5f5 ; color : #fe346e; text-align: center; border-radius: 100px 100px;\">Sentence Embedding</h3>\n",
    "<br>\n",
    "<h4 style = \"font-size:40px; font-family:Garamond ; font-weight : normal; background-color: #f6f5f5 ; color : #fe346e; text-align: center; border-radius: 100px 100px;\">Loading pretrained word embeddings and mapping them</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f069e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment below lines to download word embeddings from glove\n",
    "# !wget http://nlp.stanford.edu/data/glove.6B.zip\n",
    "# !unzip -q glove.6B.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "39f17f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "glovePath = \"glove.6B.300d.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8d4fb5e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13.4 s, sys: 2.78 s, total: 16.2 s\n",
      "Wall time: 18.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "wordEmbeddings = {}\n",
    "with open(glovePath) as f:\n",
    "    for line in f:\n",
    "        wordVec = line.split()\n",
    "        word = wordVec[0]\n",
    "        vec = list(map(float, wordVec[1:]))\n",
    "        wordEmbeddings[word] = vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9af5509",
   "metadata": {},
   "source": [
    "<span style=\"color:brown; font-size:16px\">We already applied text preprocessing on question2 which is our data and question1 in dataH which is our queries or test data.</span>\n",
    "<br> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d594ee2",
   "metadata": {},
   "source": [
    "<h4 style = \"font-size:40px; font-family:Garamond ; font-weight : normal; background-color: #f6f5f5 ; color : #fe346e; text-align: center; border-radius: 100px 100px;\">Generating average Sentence Embeddings</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "370609ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenerateAverageSentenceEmbedding:\n",
    "    def __init__(self, dimensionLen):\n",
    "        self.averageSentenceEmbedding = {}\n",
    "        self.sumWordEmbeddingVector = np.zeros(dimensionLen)\n",
    "    \n",
    "    def generateEmbeddings(self, sentenceList, preTrainedWordEmbeddings):\n",
    "        for sentence in sentenceList:\n",
    "            lenWords = 0\n",
    "            for w in sentence.split():\n",
    "                lenWords += 1\n",
    "                # sum of all the vectors for that word embedding\n",
    "                if w in preTrainedWordEmbeddings:\n",
    "                    self.sumWordEmbeddingVector = np.add(self.sumWordEmbeddingVector, preTrainedWordEmbeddings.get(w))\n",
    "            self.averageSentenceEmbedding[sentence] = (self.sumWordEmbeddingVector / lenWords)\n",
    "        return self.averageSentenceEmbedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dab7f51",
   "metadata": {},
   "source": [
    "<h4 style = \"font-size:40px; font-family:Garamond ; font-weight : normal; background-color: #f6f5f5 ; color : #fe346e; text-align: center; border-radius: 100px 100px;\">Generate sentence Embedding for data from question2</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bcab5493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15.1 s, sys: 557 ms, total: 15.7 s\n",
      "Wall time: 16.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "q2List = data.question2.to_list()\n",
    "q2Instance = GenerateAverageSentenceEmbedding(len(wordEmbeddings.get(\"of\")))\n",
    "dataEmbeddings = q2Instance.generateEmbeddings(q2List, wordEmbeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b67e5a",
   "metadata": {},
   "source": [
    "<h4 style = \"font-size:40px; font-family:Garamond ; font-weight : normal; background-color: #f6f5f5 ; color : #fe346e; text-align: center; border-radius: 100px 100px;\">Generate Sentence Embedding for input query data from question1 in dataH</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "56b9e013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15.1 ms, sys: 5.21 ms, total: 20.3 ms\n",
      "Wall time: 24.3 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "q1List = dataH.question1.to_list()\n",
    "queryInstance = GenerateAverageSentenceEmbedding(len(wordEmbeddings.get(\"of\")))\n",
    "queryEmbeddings = queryInstance.generateEmbeddings(q1List, wordEmbeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86441f05",
   "metadata": {},
   "source": [
    "<h4 style = \"font-size:40px; font-family:Garamond ; font-weight : normal; background-color: #f6f5f5 ; color : #fe346e; text-align: center; border-radius: 100px 100px;\">Calculate Cosine Similarity</h4>\n",
    "<h5 style = \"font-size:20px; font-family:Garamond ; font-weight : normal; background-color: #f6f5f5 ; color : #fe346e; text-align: center; border-radius: 10px 10px;\">The cosine similarity gives the closeness of each input query to our data</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "92f32042",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCosineSimilarity(x, y):\n",
    "    cosineSimilarity = np.dot(x, y) / ((sum(x**2)**0.5) * (sum(y**2)**0.5))\n",
    "    return cosineSimilarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738da9de",
   "metadata": {},
   "source": [
    "<h4 style = \"font-size:40px; font-family:Garamond ; font-weight : normal; background-color: #f6f5f5 ; color : #fe346e; text-align: center; border-radius: 100px 100px;\">Text Matching</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "13d8291b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11min 54s, sys: 3.59 s, total: 11min 57s\n",
      "Wall time: 11min 57s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "resultTop5SE = {}\n",
    "resultTop2SE = {}\n",
    "for k, q in queryEmbeddings.items():\n",
    "    cose = []\n",
    "    for dataEmb in dataEmbeddings.values():\n",
    "        cose.append(getCosineSimilarity(q, dataEmb))  \n",
    "    resultTop5SE[k] = [np.argpartition(cose, -5)[-5:]]\n",
    "    resultTop2SE[k] = [np.argpartition(cose, -2)[-2:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cf962ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"sentenceEmbeddingOutput.txt\", \"w\") as f:\n",
    "    for q, v in resultTop5SE.items():\n",
    "        docId = dataH[dataH.question1 == q].id.to_list()[0]\n",
    "        originalInputQuery = originalData[originalData.id==docId].question1.to_list()[0]\n",
    "        q2 = originalData.iloc[resultTop5SE[q][0]].question2.to_list()\n",
    "        f.write(\"******************\\n\")\n",
    "        f.write(f\"{originalInputQuery}\\n\")\n",
    "        f.write(f\"{q2}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490b5e14",
   "metadata": {},
   "source": [
    "<h3 style = \"font-size:60px; font-family:Garamond ; font-weight : normal; background-color: #f6f5f5 ; color : #fe346e; text-align: center; border-radius: 100px 100px;\">Performance Evaluation</h3>\n",
    "<br>\n",
    "<br>\n",
    "<span style=\"font-size:25px; font-family:Garamond ; font-weight : normal; background-color: #f6f5f5 ; color : #fe346e; border-radius: 30px 30px\">Probability top5 vs top2</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "18024253",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProbabilitySentenceEmbedding:\n",
    "    def __init__(self, totalLen):\n",
    "        self.totalLen = totalLen\n",
    "        self.truth = 0\n",
    "    \n",
    "    def getProbability(self, result, dataH, originalData):\n",
    "        for q, f in result.items():\n",
    "            docIds = dataH[dataH.question1 == q].id.to_list()[0]\n",
    "            originalDocIds = originalData.iloc[result[q][0]].id.to_list()\n",
    "            if docIds in originalDocIds:\n",
    "                self.truth += 1\n",
    "        return (self.truth / self.totalLen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "296cd129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence Embedding Probability for ground truth with top 5 docs is 0.28\n",
      "Sentence Embedding Probability for ground truth with top 2 docs is 0.12\n"
     ]
    }
   ],
   "source": [
    "top5SEInstance = ProbabilitySentenceEmbedding(len(q1List))\n",
    "top5SEProb = top5SEInstance.getProbability(resultTop5SE, dataH, originalData)\n",
    "top2SEIntance = ProbabilitySentenceEmbedding(len(q1List))\n",
    "top2SEProb = top2SEIntance.getProbability(resultTop2SE, dataH, originalData)\n",
    "print(f\"Sentence Embedding Probability for ground truth with top 5 docs is {top5SEProb}\")\n",
    "print(f\"Sentence Embedding Probability for ground truth with top 2 docs is {top2SEProb}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4be2b1",
   "metadata": {},
   "source": [
    "<h3 style = \"font-size:60px; font-family:Garamond ; font-weight : normal; background-color: #f6f5f5 ; color : #fe346e; text-align: center; border-radius: 100px 100px;\">Search question Sentence Embedding</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c9027f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def searchQuestionSentenceEmbedding(question, wordEmbeddings, dataEmbeddings, originalData):\n",
    "    # it should go through text preprocessing phase\n",
    "    question = remove_punctuation(question)\n",
    "    question = remove_numbers(question)\n",
    "    question = remove_html_tags(question)\n",
    "    question = remove_urls(question)\n",
    "    question = convert_to_lowercase(question)\n",
    "    question = apply_tokenization_and_remove_stopwords(question)\n",
    "    question = apply_lemmatization(question)\n",
    "    \n",
    "    instanceQ = GenerateAverageSentenceEmbedding(len(wordEmbeddings.get(\"of\")))\n",
    "    qEmbeddings = instanceQ.generateEmbeddings([question], wordEmbeddings)\n",
    "    \n",
    "    searchQuestionTop5 = {}\n",
    "    for k, q in qEmbeddings.items():\n",
    "        cose = []\n",
    "        for dataEmb in dataEmbeddings.values():\n",
    "            cose.append(getCosineSimilarity(q, dataEmb))  \n",
    "        searchQuestionTop5[k] = [np.argpartition(cose, -5)[-5:]]\n",
    "    \n",
    "        t = originalData.iloc[searchQuestionTop5[k][0]].question2.to_list()\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c011a636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your Question: How to do MBBS?\n",
      "CPU times: user 7.15 s, sys: 255 ms, total: 7.41 s\n",
      "Wall time: 17.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "question = input(\"Enter your Question: \")\n",
    "top5MatchesSentenceEmbedding = searchQuestionSentenceEmbedding(\n",
    "    question, \n",
    "    wordEmbeddings.copy(), \n",
    "    dataEmbeddings,\n",
    "    originalData\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1dda92a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"I don't beleive I am bulimic, but I force throw up atleast once a day after I eat something and feel guilty. Should I tell somebody, and if so who?\",\n",
       " 'How do you control your horniness?',\n",
       " 'Would a second airport in Sydney, Australia be needed if a high-speed rail link was created between Melbourne and Sydney?',\n",
       " 'Which level of prepration is enough for the exam jlpt5?',\n",
       " \"What's the difference between an artist and an artisan?\"]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top5MatchesSentenceEmbedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ca42af",
   "metadata": {},
   "source": [
    "<h3 style = \"font-size:60px; font-family:Garamond ; font-weight : normal; background-color: #f6f5f5 ; color : #fe346e; text-align: center; border-radius: 100px 100px;\">Sentence Embedding with DownWeight Frequent Words</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "77537b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenerateDownWeightSentenceEmbedding:\n",
    "    def __init__(self, dimensionLen):\n",
    "        self.downWeightSentenceEmbedding = {}\n",
    "        self.sumWordEmbeddingVector = np.zeros(dimensionLen)\n",
    "        self.probWMap = {}\n",
    "    \n",
    "    def probabilityW(self, sentenceList):\n",
    "        countTotalWords = 0\n",
    "        for sentence in sentenceList:\n",
    "            for w in sentence.split():\n",
    "                countTotalWords += 1\n",
    "                if w not in self.probWMap:\n",
    "                    self.probWMap[w] = 1\n",
    "                else:\n",
    "                    self.probWMap[w] += 1\n",
    "        for w in self.probWMap:\n",
    "            self.probWMap[w] = self.probWMap[w] / countTotalWords\n",
    "        \n",
    "            \n",
    "    def generateEmbeddings(self, sentenceList, preTrainedWordEmbeddings):\n",
    "        a = 10 ** -4\n",
    "        # First calculate probability of w\n",
    "        self.probabilityW(sentenceList)\n",
    "        for sentence in sentenceList:\n",
    "            lenWords = 0\n",
    "            for w in sentence.split():\n",
    "                lenWords += 1\n",
    "                downWeight = (a/(a + self.probWMap[w]))\n",
    "                if w in preTrainedWordEmbeddings:\n",
    "                    self.sumWordEmbeddingVector = self.sumWordEmbeddingVector * downWeight\n",
    "                    # sum of all the vectors for that word embedding\n",
    "                    self.sumWordEmbeddingVector = np.add(self.sumWordEmbeddingVector,preTrainedWordEmbeddings.get(w))\n",
    "            self.downWeightSentenceEmbedding[sentence] = self.sumWordEmbeddingVector / lenWords\n",
    "        return self.downWeightSentenceEmbedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02151376",
   "metadata": {},
   "source": [
    "<h4 style = \"font-size:40px; font-family:Garamond ; font-weight : normal; background-color: #f6f5f5 ; color : #fe346e; text-align: center; border-radius: 100px 100px;\">Generate sentence Embedding for data from question2</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fa8e3faf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16.4 s, sys: 742 ms, total: 17.1 s\n",
      "Wall time: 17.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "q2List = data.question2.to_list()\n",
    "q2Instance = GenerateDownWeightSentenceEmbedding(len(wordEmbeddings.get(\"of\")))\n",
    "downWeightDataEmbeddings = q2Instance.generateEmbeddings(q2List, wordEmbeddings.copy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fbff2a4",
   "metadata": {},
   "source": [
    "<h4 style = \"font-size:40px; font-family:Garamond ; font-weight : normal; background-color: #f6f5f5 ; color : #fe346e; text-align: center; border-radius: 100px 100px;\">Generate Sentence Embedding for input query data from question1 in dataH</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "05074996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.2 ms, sys: 9.16 ms, total: 21.3 ms\n",
      "Wall time: 24.5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "q1List = dataH.question1.to_list()\n",
    "queryInstance = GenerateDownWeightSentenceEmbedding(len(wordEmbeddings.get(\"of\")))\n",
    "queryEmbeddings = queryInstance.generateEmbeddings(q1List, wordEmbeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be6ea1c",
   "metadata": {},
   "source": [
    "<h4 style = \"font-size:40px; font-family:Garamond ; font-weight : normal; background-color: #f6f5f5 ; color : #fe346e; text-align: center; border-radius: 100px 100px;\">Calculate Cosine Similarity</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "82fd3866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11min 53s, sys: 3.36 s, total: 11min 56s\n",
      "Wall time: 11min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "resultTop5 = {}\n",
    "resultTop2 = {}\n",
    "for k, q in queryEmbeddings.items():\n",
    "    cose = []\n",
    "    for dataEmb in downWeightDataEmbeddings.values():\n",
    "        cose.append(getCosineSimilarity(q, dataEmb))  \n",
    "    resultTop5[k] = [np.argpartition(cose, -5)[-5:]]\n",
    "    resultTop2[k] = [np.argpartition(cose, -2)[-2:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a288473",
   "metadata": {},
   "source": [
    "<h3 style = \"font-size:60px; font-family:Garamond ; font-weight : normal; background-color: #f6f5f5 ; color : #fe346e; text-align: center; border-radius: 100px 100px;\">Performance Evaluation</h3>\n",
    "<br>\n",
    "<br>\n",
    "<span style=\"font-size:25px; font-family:Garamond ; font-weight : normal; background-color: #f6f5f5 ; color : #fe346e; border-radius: 30px 30px\">Probability top5 vs top2</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f75933dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DownWeightSEProbability:\n",
    "    def __init__(self, totalLen):\n",
    "        self.totalLen = totalLen\n",
    "        self.truth = 0\n",
    "        \n",
    "    def getProbability(self, result, dataH, originalData):\n",
    "        \n",
    "        for q, f in result.items():\n",
    "            c = 0\n",
    "            docIds = dataH[dataH.question1 == q].id.to_list()[0]\n",
    "            originalDocIds = originalData.iloc[result[q][0]].id.to_list()\n",
    "            if docIds in originalDocIds:\n",
    "                self.truth += 1\n",
    "        return (self.truth / self.totalLen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4aa4f997",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtop5Instance = DownWeightSEProbability(len(q1List))\n",
    "dtop5 = dtop5Instance.getProbability(resultTop5, dataH, originalData)\n",
    "dtop5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f97e0a37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtop2Instance = DownWeightSEProbability(len(q1List))\n",
    "dtop2 = dtop2Instance.getProbability(resultTop2, dataH, originalData)\n",
    "dtop2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bbb69104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The probability of top 5 is 0.19\n",
      "The probability of top 2 is 0.04\n"
     ]
    }
   ],
   "source": [
    "print(f\"The probability of top 5 is {dtop5}\")\n",
    "print(f\"The probability of top 2 is {dtop2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039011dd",
   "metadata": {},
   "source": [
    "<h3 style = \"font-size:30px; font-family:Garamond ; font-weight : normal; background-color: #f6f5f5 ; color : #fe346e; text-align: center; border-radius: 100px 100px;\">Matched questions</h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "102d91a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"downWeightOutput.txt\", \"w\") as f:\n",
    "    for q, v in resultTop5.items():\n",
    "        docId = dataH[dataH.question1 == q].id.to_list()[0]\n",
    "        originalInputQuery = originalData[originalData.id==docId].question1.to_list()[0]\n",
    "        q2 = originalData.iloc[resultTop5[q][0]].question2.to_list()\n",
    "        f.write(\"******************\\n\")\n",
    "        f.write(f\"{originalInputQuery}\\n\")\n",
    "        f.write(f\"{q2}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5d61b2",
   "metadata": {},
   "source": [
    "<h3 style = \"font-size:60px; font-family:Garamond ; font-weight : normal; background-color: #f6f5f5 ; color : #fe346e; text-align: center; border-radius: 100px 100px;\">Search Question</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6c16b135",
   "metadata": {},
   "outputs": [],
   "source": [
    "def searchQuestionDownWeight(question, wordEmbeddings, downWeightDataEmbeddings, originalData):\n",
    "    # it should go through text preprocessing phase\n",
    "    question = remove_punctuation(question)\n",
    "    question = remove_numbers(question)\n",
    "    question = remove_html_tags(question)\n",
    "    question = remove_urls(question)\n",
    "    question = convert_to_lowercase(question)\n",
    "    question = apply_tokenization_and_remove_stopwords(question)\n",
    "    question = apply_lemmatization(question)\n",
    "    \n",
    "    instance = GenerateDownWeightSentenceEmbedding(len(wordEmbeddings.get(\"of\")))\n",
    "    qEmbeddings = instance.generateEmbeddings([question], wordEmbeddings)\n",
    "    \n",
    "    searchQuestionTop5 = {}\n",
    "    for k, q in qEmbeddings.items():\n",
    "        cose = []\n",
    "        for dataEmb in downWeightDataEmbeddings.values():\n",
    "            cose.append(getCosineSimilarity(q, dataEmb))  \n",
    "        searchQuestionTop5[k] = [np.argpartition(cose, -5)[-5:]]\n",
    "    \n",
    "        t = originalData.iloc[searchQuestionTop5[k][0]].question2.to_list()\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d19c30ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter Question: How to do MBBS?\n",
      "CPU times: user 7.12 s, sys: 325 ms, total: 7.44 s\n",
      "Wall time: 13.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "question = input(\"Enter Question: \")\n",
    "downWeightTop5MatchedQuestions = searchQuestionDownWeight(\n",
    "    question, \n",
    "    wordEmbeddings.copy(), \n",
    "    downWeightDataEmbeddings,\n",
    "    originalData\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4adc0a73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['How can I escape boredom?',\n",
       " 'How is Reliance Jio providing free unlimited 4G data when other companies charge high?',\n",
       " 'How does one start a small business?',\n",
       " \"What's the difference between an artist and an artisan?\",\n",
       " \"What is the meaning of Hindi word 'Gaddar'?\"]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "downWeightTop5MatchedQuestions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
